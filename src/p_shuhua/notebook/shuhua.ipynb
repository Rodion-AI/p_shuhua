{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19f07d1e",
   "metadata": {},
   "source": [
    "# task:\n",
    "\n",
    "Create a neuro-salesperson to process a cold customer base in Telegram."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bf3188",
   "metadata": {},
   "source": [
    "# preparing the enviroment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b60d241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library's\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "load_dotenv(\".env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36c1d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import questions for test\n",
    "path_download = \"https://drive.google.com/uc?export=download&id=\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661fda60",
   "metadata": {},
   "source": [
    "# agent's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c4e664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial client\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd348282",
   "metadata": {},
   "source": [
    "## moderator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9bc2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write model\n",
    "model_for_moderator = \"\"\"\n",
    "omni-moderation-latest\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3006e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def moderator(model: str, ans: str, context: str, verbose=1):\n",
    "    \"\"\"function for agent - moderator\"\"\"\n",
    "\n",
    "    text = context + ans\n",
    "\n",
    "    response = client.moderations.create(model=model, input=text)\n",
    "    answer = response.results[0]\n",
    "    return answer, response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bc0487",
   "metadata": {},
   "source": [
    "## router"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dab6877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write role, model, temperature for agent router\n",
    "system_for_router = \"\"\"\n",
    "Ты великоплепный диспетчер. У тебя прекрасно получается определять кому \n",
    "из агентов передавать получаемый текст. \n",
    "\n",
    "Ты знаешь что:\n",
    "- агент communicate - отвечает за представление, презентацию, обработку возражений, \n",
    "приглашение на встречу по зуму.\n",
    "- агент zoom - отвечает за организацию встречи по зуму.\n",
    "\"\"\"\n",
    "model_for_router = \"\"\"\n",
    "gpt-5-mini-2025-08-07\n",
    "\"\"\"\n",
    "temperature_for_router = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616f9211",
   "metadata": {},
   "outputs": [],
   "source": [
    "def router(\n",
    "    system: str, model: str, temperature: float, ans: str, context: str, verbose=1\n",
    "):\n",
    "    \"\"\"function for agent - router\"\"\"\n",
    "\n",
    "    user = f\"\"\"\n",
    "    Пожалуйста, давай действовать последовательно:\n",
    "    1. Проанализируй контекст диалога.\n",
    "    2. Проанализируй полученное сообщение.\n",
    "    3. Выведи название агента: communicate или zoom.\n",
    "\n",
    "    Контекст: {context}\n",
    "    Сообщение: {ans}\n",
    "    \"\"\"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system},\n",
    "        {\"role\": \"user\", \"content\": user},\n",
    "    ]\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=model, messages=messages, temperature=temperature  # type: ignore\n",
    "    )\n",
    "\n",
    "    answer = completion.choices[0].message.content\n",
    "\n",
    "    if verbose:\n",
    "        print(\"\\n router: \\n\", answer)\n",
    "\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2becc0",
   "metadata": {},
   "source": [
    "## seller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f3ac8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write role, model, temperature for agent consult\n",
    "system_for_seller = \"\"\"\n",
    "Тебя зовут Дарья, ты менеджер по продажам работающий \n",
    "\"\"\"\n",
    "model_for_seller = \"\"\"\n",
    "gpt-5-mini-2025-08-07\n",
    "\"\"\"\n",
    "temperature_for_seller = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc270eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seller(\n",
    "    system: str, model: str, temperature: float, ans: str, context: str, verbose=1\n",
    "):\n",
    "    \"\"\"function for agent - seller\"\"\"\n",
    "\n",
    "    user = f\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system},\n",
    "        {\"role\": \"user\", \"content\": user},\n",
    "    ]\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=model, messages=messages, temperature=temperature  # type: ignore\n",
    "    )\n",
    "\n",
    "    answer = completion.choices[0].message.content\n",
    "\n",
    "    if verbose:\n",
    "        print(\"\\n seller: \\n\", answer)\n",
    "\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b506bb0c",
   "metadata": {},
   "source": [
    "## zoom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4477d888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write role, model, temperature for agent zoom\n",
    "system_for_zoom = \"\"\"\n",
    "\n",
    "\"\"\"\n",
    "model_for_zoom = \"\"\"\n",
    "\n",
    "\"\"\"\n",
    "temperature_for_zoom = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314bb035",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zoom(\n",
    "    system: str, model: str, temperature: float, ans: str, context: str, verbose=1\n",
    "):\n",
    "    \"\"\"function for agent zoom\"\"\"\n",
    "\n",
    "    user = f\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system},\n",
    "        {\"role\": \"user\", \"content\": user},\n",
    "    ]\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=model, messages=messages, temperature=temperature  # type: ignore\n",
    "    )\n",
    "\n",
    "    answer = completion.choices[0].message.content\n",
    "\n",
    "    if verbose:\n",
    "        print(\"\\n zoom \\n\", answer)\n",
    "\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349dd938",
   "metadata": {},
   "source": [
    "## goodbye"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b37ebed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write role, model, temperature for agent goodbye\n",
    "system_for_goodbye = \"\"\"\n",
    "\n",
    "\"\"\"\n",
    "model_for_goodbye = \"\"\"\n",
    "\n",
    "\"\"\"\n",
    "temperature_for_goodbye = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f1737a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def goodbye(\n",
    "    system: str, model: str, temperature: float, ans: str, context: str, verbose=1\n",
    "):\n",
    "    \"\"\"function for agent goodbye\"\"\"\n",
    "\n",
    "    user = f\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system},\n",
    "        {\"role\": \"user\", \"content\": user},\n",
    "    ]\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=model, messages=messages, temperature=temperature  # type: ignore\n",
    "    )\n",
    "\n",
    "    answer = completion.choices[0].message.content\n",
    "\n",
    "    if verbose:\n",
    "        print(\"\\n goodbye \\n \", answer)\n",
    "\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932b6889",
   "metadata": {},
   "source": [
    "# neuro assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f981a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function of neuro assistant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e8ebd2",
   "metadata": {},
   "source": [
    "# тесты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068fbb26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "poetry: p_shuhua",
   "language": "python",
   "name": "p_shuhua"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
